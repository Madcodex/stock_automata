{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kite_trade import *\n",
    "import os\n",
    "# import ta\n",
    "from tqdm import tqdm\n",
    "import util_fun as uf\n",
    "from enctoken import get_kite\n",
    "kite = get_kite()\n",
    "import sqlite3\n",
    "from swifter import set_defaults\n",
    "set_defaults(\n",
    "    progress_bar=False,\n",
    "\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timerframe_list = [\n",
    "\"day\",\n",
    "\"minute\",\n",
    " \"3minute\",\n",
    " \"5minute\",\n",
    " \"10minute\",\n",
    " \"15minute\",\n",
    " \"30minute\",\n",
    " \"60minute\",]\n",
    "\n",
    "i=1\n",
    "error_list = []\n",
    "# instument in nse\n",
    "inst = pd.DataFrame(kite.instruments(\"NSE\"))\n",
    "inst_filter = inst.query('(name != \"\")').copy()\n",
    "inst_filter.rename(columns = {\"tradingsymbol\":'Symbol'},inplace = True)\n",
    "# inst_filter.query(\"Symbol == 'HDFCBANK'\")\n",
    "\n",
    "nifty_500 = pd.read_csv('../data/ind_nifty500list.csv')\n",
    "nifty_500 = nifty_500.merge(inst_filter, on = 'Symbol')\n",
    "# inst_filter = inst_filter.query('segment == \"NSE\" and instrument_type == \"EQ\"')\n",
    "inst_dict = dict(zip(nifty_500.Symbol, nifty_500.instrument_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_data(kite, instrument, time_frame, start_date,end_date):\n",
    "    results = pd.DataFrame()\n",
    "    df = pd.DataFrame(kite.historical_data(instrument,start_date, end_date,time_frame))\n",
    "    results = results.append(df) \n",
    "    return results\n",
    "\n",
    "def get_data_parllel(kite, instrument, time_frame, start_date, end_date):\n",
    "    df_final = pd.DataFrame()\n",
    "    temp_sd = pd.to_datetime(start_date).strftime('%Y-%m-01')\n",
    "    if (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days > 28:\n",
    "        df = pd.DataFrame(pd.date_range(temp_sd ,end_date,freq=\"MS\")).rename(columns={0:'start_date'})\n",
    "        df['end_date'] = df.shift(-1)\n",
    "        df['end_date'].fillna(pd.to_datetime(end_date), inplace=True)\n",
    "    else:\n",
    "        df = pd.DataFrame({\"start_date\": pd.to_datetime(start_date), \"end_date\": pd.to_datetime(end_date)}, index=[0])\n",
    "    \n",
    "    df['tf'] = time_frame\n",
    "    df['inst'] = instrument\n",
    "    df['fetch_data'] = df.swifter.apply(lambda x: pd.DataFrame(kite.historical_data(x['inst'], x['start_date'], x['end_date'], x['tf'])),axis = 1)\n",
    "    for i in df['fetch_data']:\n",
    "        df_final = df_final.append(i)\n",
    "    df_final.rename(columns = {'date': \"Date\",'close':'Close', 'high':'High', 'low':\"Low\", 'open': \"Open\",\"volume\":\"Volume\"}, inplace = True)\n",
    "    df_final= df_final[(pd.to_datetime(df_final['Date'].dt.date) >= pd.to_datetime(start_date)) &  \\\n",
    "                      (pd.to_datetime(df_final['Date'].dt.date) <= pd.to_datetime(end_date))]\n",
    "    df_final.set_index('Date', inplace=True)\n",
    "    return df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:38<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "today_date = '2023-05-30'\n",
    "start_dt = '2023-05-30'\n",
    "end_dt = '2023-05-31'\n",
    "time_frame = '15minute'\n",
    "\n",
    "# import sql \n",
    "# conn = sql.create_connection('../data/Nifty_500.db')\n",
    "# cursor_obj = conn.cursor()\n",
    "# sql.delete_table(conn,'fivteen_minute')\n",
    "df_all = pd.DataFrame()\n",
    "for symbol, instument in tqdm(inst_dict.items()):\n",
    "    if i:\n",
    "        # print(symbol, instument)\n",
    "        try:\n",
    "            df_all = df_all.append(get_data_parllel(kite, instument, time_frame , start_dt,end_dt).assign(stock = symbol))\n",
    "            # df_day['stock'] = symbol\n",
    "            # df_all = df_all.append(df_day)\n",
    "            # df_all.reset_index(drop = True)\n",
    "            # df_day.to_sql('fivteen_minute',conn, if_exists=\"append\",index = True, index_label = 'Date')\n",
    "            \n",
    "                # directory = f'../data/historical/{time_frame}/{symbol}'\n",
    "                # if not os.path.exists(directory):\n",
    "                #     os.makedirs(directory)\n",
    "                # df_day.to_parquet(f'{directory}/part0.parquet')\n",
    "        except:\n",
    "                print(instument)\n",
    "                error_list.append(instument)\n",
    "\n",
    "    # break\n",
    "\n",
    "    i += 1\n",
    "print(error_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_parquet('data_30may_15min.parquet')\n",
    "df_all = pd.read_parquet('data_30may_15min.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = sql.sql_to_pd(conn,\"fivteen_minute\" )\n",
    "df_all = df_all.reset_index()\n",
    "df_all['Date']  = pd.to_datetime(df_all['Date']).dt.tz_localize(None)\n",
    "df_all['date_only'] = pd.to_datetime(df_all['Date'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>stock</th>\n",
       "      <th>date_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-30 09:00:00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>2023-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-30 09:15:00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>24300.00</td>\n",
       "      <td>24160.00</td>\n",
       "      <td>24234.25</td>\n",
       "      <td>115</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>2023-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-30 09:30:00</td>\n",
       "      <td>24234.25</td>\n",
       "      <td>24244.55</td>\n",
       "      <td>24190.00</td>\n",
       "      <td>24239.00</td>\n",
       "      <td>41</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>2023-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-30 09:45:00</td>\n",
       "      <td>24239.00</td>\n",
       "      <td>24240.00</td>\n",
       "      <td>24171.15</td>\n",
       "      <td>24199.95</td>\n",
       "      <td>40</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>2023-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-30 10:00:00</td>\n",
       "      <td>24199.95</td>\n",
       "      <td>24220.00</td>\n",
       "      <td>24193.30</td>\n",
       "      <td>24220.00</td>\n",
       "      <td>57</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>2023-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date      Open      High       Low     Close  Volume  \\\n",
       "0 2023-05-30 09:00:00  24160.00  24160.00  24160.00  24160.00       0   \n",
       "1 2023-05-30 09:15:00  24160.00  24300.00  24160.00  24234.25     115   \n",
       "2 2023-05-30 09:30:00  24234.25  24244.55  24190.00  24239.00      41   \n",
       "3 2023-05-30 09:45:00  24239.00  24240.00  24171.15  24199.95      40   \n",
       "4 2023-05-30 10:00:00  24199.95  24220.00  24193.30  24220.00      57   \n",
       "\n",
       "     stock  date_only  \n",
       "0  3MINDIA 2023-05-30  \n",
       "1  3MINDIA 2023-05-30  \n",
       "2  3MINDIA 2023-05-30  \n",
       "3  3MINDIA 2023-05-30  \n",
       "4  3MINDIA 2023-05-30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = df_all[df_all.stock.isin(nifty_500.Symbol.unique())]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 candle breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_six_candle_setup(df):\n",
    "    try:\n",
    "        # print(df.loc[df.Date.dt.time == pd.to_datetime('09:15:00').time(),'High'].unique()[0] )\n",
    "        f_high = df.loc[df.Date.dt.time == pd.to_datetime('09:15:00').time(),'High'].unique()[0] \n",
    "        f_low = df.loc[df.Date.dt.time == pd.to_datetime('09:15:00').time(),'Low'].unique()[0]\n",
    "        df['f_high'] = f_high\n",
    "        df[\"f_low\"] = f_low\n",
    "        df['per_chg'] = (abs(f_high - f_low)/ f_low) * 100\n",
    "        df['break_f_high'] = np.where(df['High'] > df['f_high'], \"brk\", 'not_b')\n",
    "        df['break_f_low'] = np.where(df['Low'] < df['f_low'],\"brk\", 'not_b')\n",
    "        df['break_any_side'] = np.where((df['break_f_high'] == 'not_b') & (df['break_f_low'] == 'not_b'),'not_b',\"brk\") \n",
    "        # print(df)\n",
    "        # return df\n",
    "        first_five_candle = df.loc[df.Date.dt.time <= pd.to_datetime('10:30:00').time(),'break_any_side'].unique()\n",
    "        for i in first_five_candle:\n",
    "            if 'brk' in i:\n",
    "                return [False,df['per_chg'].unique()[0]]\n",
    "        return [True,df['per_chg'].unique()[0]]\n",
    "    except:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wipro = df_all[(df_all.date_only == '2023-05-05') & (df_all.stock == 'CGCL')]\n",
    "# df_filter_w = df_wipro.groupby(['date_only','stock']).apply(first_six_candle_setup).reset_index().rename(columns={0:\"flag\"})\n",
    "\n",
    "df_filter = df_all.groupby(['date_only','stock']).apply(first_six_candle_setup).reset_index().rename(columns={0:\"flag\"})\n",
    "df_filter = pd.concat([df_filter.drop('flag', axis= 1),df_filter.flag.apply(pd.Series).rename(columns = {0 :'flag', 1: 'per_chg'})],axis = 1)\n",
    "\n",
    "# sort by first candle minimum % chg\n",
    "df_selected = df_filter[(df_filter.flag) & (df_filter.date_only == today_date)].sort_values('per_chg')#.head(50)\n",
    "df_first_candle = df_all.loc[df_all.Date.dt.time == pd.to_datetime('09:15:00').time(),:]\n",
    "df_selected = df_selected.merge(df_first_candle, how  = 'left', on = ['date_only','stock'])\n",
    "df_selected['ltp_cols'] = \"NSE\" + \":\" +df_selected['stock']\n",
    "df_selected = df_selected[df_selected.Open.between(100,5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUNTV', 'COROMANDEL', 'MOIL', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "['COROMANDEL', 'MOIL', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "sending message\n",
      "['SUNTV', 'COROMANDEL', 'MOIL', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'COFORGE', 'EPL', 'NCC']\n",
      "['SUNTV', 'MOIL', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "sending message\n",
      "['SUNTV', 'MOIL', 'REDINGTON', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'COFORGE', 'EPL', 'NCC']\n",
      "['SUNTV', 'MOIL', 'REDINGTON', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "sending message\n",
      "['SUNTV', 'COROMANDEL', 'MOIL', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "sending message\n",
      "['SUNTV', 'MOIL', 'KEI', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'POWERGRID', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "['SUNTV', 'MOIL', 'KEI', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['TEAMLEASE', 'POWERGRID', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "sending message\n",
      "['SUNTV', 'MOIL', 'KEI', 'REDINGTON', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['FEDERALBNK', 'TEAMLEASE', 'POWERGRID', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n",
      "['SUNTV', 'MOIL', 'KEI', 'REDINGTON', 'MAZDOCK', 'HOMEFIRST', 'MHRIL', 'SUPRAJIT']\n",
      "['FEDERALBNK', 'TEAMLEASE', 'HEG', 'HINDPETRO', 'DRREDDY', 'ZYDUSLIFE', 'EPL', 'NCC']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12588\\4266937770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# ws.range(\"A1\").options(index=False).value = df_selected_up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# ws.range(f\"A{df_selected_up.shape[0]+3}\").options(index=False).value = df_selected_down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m# break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "# import xlwings as xw\n",
    "# wb=xw.Book(\"../data/five_candle.xlsx\")\n",
    "# ws = wb.sheets[\"Sheet1\"]\n",
    "\n",
    "alrady_break_up = []\n",
    "alrady_break_down = []\n",
    "i = 0 \n",
    "while(True):\n",
    "    df_selected['ltp'] = df_selected['ltp_cols'].map(kite.ltp(df_selected.ltp_cols.unique().tolist())).apply(lambda x: x['last_price'])\n",
    "    \n",
    "    # if i == 0:\n",
    "    #     print(i)\n",
    "    #     i +=1\n",
    "    #     df_selected_1 = df_selected[~((df_selected['ltp'] < df_selected['High']) &  (df_selected['ltp'] > df_selected['Low']))]\n",
    "    #     df_selected_1['break_time'] = datetime.datetime.now().time()\n",
    "    #     alrady_break.append(df_selected_1.stock.unique().tolist())\n",
    "    df_selected['quantity'] =(45000/df_selected['ltp']) * 5\n",
    "    df_selected['near_High'] = df_selected['High'] - df_selected['High']  * .001\n",
    "    df_selected['near_low'] = df_selected['Low'] + df_selected['Low']  * .001\n",
    "    df_selected_up = df_selected[(df_selected['ltp'] > df_selected['High'])]\n",
    "    df_selected_down  =  df_selected[(df_selected['ltp'] < df_selected['Low'])]\n",
    "    if i != 0:\n",
    "        alert_list = list(set(df_selected_up.stock.unique().tolist()) - set(alrady_break_up))  + list(set(df_selected_down.stock.unique().tolist()) - set(alrady_break_down))\n",
    "        if alert_list != []:\n",
    "            print(\"sending message\")\n",
    "            # uf.alert_msg(df_selected[df_selected.stock.isin(alert_list)][['stock','ltp','quantity']],0,0)\n",
    "            uf.telegram_msg(df_selected[df_selected.stock.isin(alert_list)][['stock','ltp','quantity']].round(0).values)\n",
    "\n",
    "    alrady_break_up = df_selected_up.stock.unique().tolist()\n",
    "    alrady_break_down = df_selected_down.stock.unique().tolist()\n",
    "    \n",
    "    # df_selected_2 = df_selected_2.merge(df_selected_1[['date_only','stock','break_time']], how = 'left', on = ['date_only','stock'])\n",
    "    # df_selected_2['break_time'] = np.where(df_selected_2.stock.isin(alrady_break),df_selected_2['break_time'],datetime.datetime.now().time() )\n",
    "    # alrady_break.append(df_selected_1.stock.unique().tolist())\n",
    "    # df_selected_2['break_time'] = df_selected_2['break_time'].astype(str)\n",
    "    print(df_selected_up.stock.unique().tolist())\n",
    "    print(df_selected_down.stock.unique().tolist())\n",
    "    i += 1\n",
    "    # ws.clear_contents()\n",
    "    # ws.range(\"A1\").options(index=False).value = df_selected_up\n",
    "    # ws.range(f\"A{df_selected_up.shape[0]+3}\").options(index=False).value = df_selected_down\n",
    "    time.sleep(30)\n",
    "    # break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 consecutive candle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['per_chg'] = abs(df_all['Open'] - df_all['Close'])  / df_all['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_candle_setup(df,per_chng = 0.0009):\n",
    "    # 1. get % chg in open close \n",
    "    # 2. consecutive 4 true case \n",
    "    df['fst'] = df['per_chg'].shift(-1)\n",
    "    df['scnd'] = df['per_chg'].shift(-2)\n",
    "    df['third'] = df['per_chg'].shift(-3)\n",
    "\n",
    "    # print(df)\n",
    "    df['cond_flag'] = np.where(\n",
    "        (df['fst'] <= per_chng) & \n",
    "        (df['scnd'] <= per_chng) & \n",
    "        (df['third'] <=per_chng)  & \n",
    "        (df['per_chg'] <= per_chng),\n",
    "        True,\n",
    "        False\n",
    "        )\n",
    "    # print(df)\n",
    "    return df['cond_flag'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ind = df_all[(df_all.stock == 'JSWENERGY') & (df_all.date_only == '2023-05-04')]\n",
    "# df_four_ind = df_ind.groupby(['date_only','stock']).apply(four_candle_setup).reset_index().rename(columns={0:\"flag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_date = df_all[(df_all.date_only == '2023-05-30')]\n",
    "df_four = df_part_date.groupby(['date_only','stock']).apply(four_candle_setup).reset_index().rename(columns={0:\"flag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AFFLE', 'BEL', 'BLUEDART', 'CAMS', 'CESC', 'CGCL', 'DBL', 'HDFC',\n",
       "       'HINDZINC', 'IDEA', 'KEI', 'NCC', 'PRESTIGE', 'SHRIRAMFIN',\n",
       "       'SOLARINDS', 'SUNTECK', 'TATAMTRDVR', 'TEAMLEASE', 'TEJASNET',\n",
       "       'THYROCARE', 'TITAN', 'TTML', 'VARROC', 'VINATIORGA', 'VTL',\n",
       "       'WHIRLPOOL'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_four[(df_four.flag == 1) & (df_four.date_only == '2023-05-30')].stock.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[(df_all.stock == \"JSWENERGY\") & (df_all.date_only == '2023-05-05')].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
